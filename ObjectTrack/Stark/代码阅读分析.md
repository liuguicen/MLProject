# 模块化
**模块化，且模块支持增删改换**
这个模型结构也是模块化的，模块间具有可置换性，可以对不同的部分配置不同的模块，这和一般软件工程是一样的
比如它的主干模块可以采用不同的网络主干
时间信息模块可以加入也可以不加入


一般的数据集，是把视频处理好分成帧了的
对于每个视频，可以构造一个序列对象，序列对象的元素是以视频帧为中心的各种信息，报考帧路径，对象位置，对象是否完全看不见等信息，然后还包含整个视频的一些信息

设置一个模型的装饰器，用来处理模型运行配置等工作


# transformer相关
这篇文章的encoder直接堆叠完全相同的self-attention+ffn 形成编码器
自注意力层很好添加，直接用pytorch提供的类即可，根cnn一样的
然后q k v 是要自己计算然后输入，不是自动计算的
文中提到的解码器查询输入，直接就是用的某种嵌入网络的参数

sa的长度是不限定的

# 轻量化相关
作者后来显然收到swin-transformer的启发，整了一个swin版本的transformer
  
使用repvgg作为轻量化模型的主干，这个主干主要是速度快，详见 
https://blog.csdn.net/weixin_48249563/article/details/115030808

## 轻量化transformer
输入序列向量长度128,标准版本的是256，多头数量为8不变  
后面接的FFN数量不变  
似乎只有一个编码器，但是这个感觉不科学，transformer都是具有两个解码器的呀 为什么?
编码器只一个注意力模块，而不是标准版本的堆叠6个模块   
使用了新的位置编码方式   
最后的边框预测网络使用的也是repvgg的block，包含5个卷积，其中2个是1*1 size的