**数据、标注、知识之间的关系**
对样本做标注，可以看成是一种将数据和知识做关联的工作。数据是原始的，没有加工过的信息，然后知识就是从数据中提取，加工整理过的，应用于特定领域的信息。
可以把数据看成原油，知识是从原油中提取出来的石油，化工产品等。
知识是数据的抽象，数据是知识的载体。

**数据和知识相互迭代**
这个关系反映在数据集制作过程中，就是：知识会指导数据的采集和标注，而在数据的采集和标注过程中，知识又会被修正，这是一个彼此影响、反复迭代的过程。

**“数据”需要伴随着任务也就是需求进行迭代：**
对于一个行业或者产品来说， 它的任务定义往往是模糊的。那么“数据”和“任务”需要一个长期的迭代过程，这个过程成本是相当高的。 我：做数据集之前任务没有明确细节，任务有多种可能的需求，或者任务后面发生变化，需要数据集做出对应变化，给出相应的数据。从这个角度看，“数据”需要伴随着任务也就是需求进行迭代。

**分类要平行对 标签被声明分类要互斥等**
再举一例。DeepFashion[4]是2016年发布的一个服饰图像数据集，包括了超过80万张时装照片，被归到50个类别里。这50个类别标签来自制作者从两个服饰网站的查询词中抽取的名词，这些标签被声明是互斥的，但实际情况并非如此。例如毛衣（Sweater）和龟领（Turtleneck）这两个标签，毛衣属于“材质”的范畴，而龟领属于“领子设计”的范畴，两个标签在概念上并非平行对等，不能并列作为服饰的两个类别。如图1，“龟领”类别的衣服，同时也是“毛衣”。这类错误在DeepFashion数据集中并不少见。


对于一些任务，还有专门的标注工具，比如分割，可以描出图片中的区域并打上标签。目前开源的深度学习标注工具有很多。像Labelme、Labellmg.Vatic、Sloth.ImageJ、CVAT、Yolo_mark、RectLabel和Labelbox等等。


## 要让数据集走向实用：
我们现在的深度学习依赖数据集提供的知识，从实用要求来说，要让算法走向实用，首先要让数据集走向实用。AI算法要落地实用，首先是要数据集能达到落地实用。

### 很多学术界的数据集不够实用
计算机视觉发展的时间还不长，人们像呵护孩子一样，鼓励新想法、包容不完美。**过去学术界对图像数据集的要求实际是比较低的**，数据量大一些大家就满意了。**如果按一个成熟的科研方向来要求的话，过去二十年业界所出现的数据集，远不能让人满意。绝大部分数据集，内在结构松散，外在用途不明，距离指导算法落地还比较远。** **目前学术界的论文和竞赛所依赖的数据集，距离其所宣称的作用和意义相去甚远。这点也是业界心照不宣的共识。** 确实是如此的，自己在github上找到的模型，展示起来说实验测试的准确度多高多高，实际用起来差很多，很多情况检测效果都差。估计就是他们训练和测试用的数据集都是相当理想的，和实际差很多，所以他们的实验结果远比实际表现好**

## 数据集与专业知识 
**忽视专业知识，无法做出有用的数据集**
我们把一个特定场景下的经验和规则，称为专业知识。制作某领域的一个实用的图像数据集，即是将特定场景下的知识与该场景下的图像做关联。
有的制作者虽然使用了特定领域的数据，但缺乏专业人士的指导，只是沿用学术界惯有的方法，想当然的把一些专有名词与图像做了关联。这样制作出的数据集可能与实际情况有很大偏差。
ChestX-ray8[2]是2017年发布的一个胸部X光数据集。制作者使用自然语言处理的一些手段对X光图像的报告单进行了文本挖掘，得到一系列疾病标签，把这些标签和对应的图像关联起来。专业人士LukeOakden-Rayner医生[3]指出：部分疾病标签并非通过观察医疗影像得出的，而是结合其他诊断信息综合得出的。
我：不能想当然的按照一般方法进行数据集建设，需要结合相关领域的专业人士，专业知识。

**数据集制作流程**
A. 算法人员和专业人士探讨学习，做知识的转译和重整。

B. 算法人员根据知识点采集图像。

C. 标注人员学习标注规则，对图像做标注。

D. 将标注好的图像输入机器，做训练和评测。

B:图像采集
1、对每个标签都需要一个最少的训练样本量，这个量同任务和数据都有关系，可以由经验或实验来确定。
2、数据采集常见的一种情况是**样本稀缺**：
解决方法：
数据增强，方法很多，见相关知识
扩充标签，有一些情况可以通过扩充标签解决，比如内容相同，但是标签名不同的样本，或者内容详实的样本，可以归到同一个标签下
3、结构化噪声问题
当我们采集数据时，很可能遇到一种结构化噪声的问题。
结构化噪声就是我们采集数据的过程和数据真实生成过程不一定一致，数据采集都是“有组织”的获取数据，从信息论来说，“有组织”意味着系统性的引入了新的信号，这种信号可能是噪声。而且结构化噪声的引入并非都显而易见，很多可能我们不容易。将带有结构化噪声的数据投给机器，模型会学到错误的相关性，我们要努力避免这种情况。

例子：
比如当以从某个数据源获取数据，数据带有改数据源的特有特征，比如网站获取图片带了标签
斯坦福大学的Novoa博士讨论过一个“肿瘤”和“尺子”的例子[5]，当皮肤科医生在怀疑一种病变是肿瘤时，会借助尺子来准确的测量大小，尺子会留在照片里，模型会学习到“尺子”和“肿瘤”具有相关性，而这种相关性在实际情况中显然是不存在的。
例如，在购物引擎里搜索“圆领”的衣服，夏天搜到的可能多是T恤，而在冬天搜索得到的多是毛衣，，不留意的话，“圆领”标签下就都是同一季的衣服

解决方法：
因此每当引入一种采集数据的手段时，都要小心观察所获取的数据（图像）的共性，分析这个共性部分与标签的相关性。如果相关性很强，则不是噪声，例如采集“翻领”时，考查“外套”特性，因为翻领是在衣服的开襟上设计的，而开襟的衣服一般都是外套，“翻领”和“外套”有强相关性，所以不是噪声。如果相关性很小，例如网站Logo，则显然是噪声，我们可以对图像做处理，去掉Logo区域。如果实在无法去除，可以考虑放弃这种采集方式。

C：标注
将数据和知识做关联
**这一步主要要考虑标注人员的学习成本和标注效率。**通过标注人员的反馈，算法人员一方面改进规则、补充图例，对标注人员反复出现疑问的地方，考虑知识修正；另一方面，改进标注工具，包括流程、交互、预处理等，以提高标注效率。

经过第一步和第二步，知识体系中不合理的地方已经大部分得到解决。如果在第三步中标注人员仍有困扰，往往困扰的地方可以引发我们深入思考、产生对数据更深的理解。
D:训练评测，利用模型做迭代
从D到C的迭代，关键词是“校验”，校验的是标注人员的标注质量。通常我们不会把所有数据都标注完才投给机器去训练，而是分批次标注。假设有10000个样本，我们会分2000、3000、5000三个批次。前一个批次的样本投入训练，如果模型的训练准确率达到满意，说明标注质量合格，才进行下一个批次的标注；否则要总结经验、重新标注。这样可以减少标注的试错成本。
如果改进C还是不能让模型表现足够好，还要回到B进行迭代，应对B据采集中可能出现的“样本稀缺”和“结构化噪声”问题。

我们会模拟真实使用场景，进行随机采样，这样得到的样本于环节A和B无关，我们称之为“真实场景采样”。然后将样本放到模型中进行评测，这样的样本用于评测才是正确的。评测结果经过人工审核后，如果效果达到满意，就说明模型被训练得不错（即训练数据不错），数据集的“结构化噪声”得到了较好的抑制；如果评测效果不佳，说明数据集存在着欠缺某方面的训练样本等问题，那把错例补充回数据集，继续训练，并更新真实采样后再做预测，直到效果满意为止。

指标：
数据集标注好之后，还应有一套用来评测模型的方法，就是“指标”。知识、数据、加上指标，才是一个完整的数据集。好的指标也体现了对于“实用”数据集的追求。
评测指标有很多，比如准确率与召回率，目标检测的交并比，实用中把“九分袖”错判为“七分袖”，和错判为“短袖”，错误程度是不同的，应区别对待，我们就引入了标签距离，把标注结果细化为（0,0,0,3,5,7,10,8），这样更贴近实际情况。
指标体系的丰富和细化，其实是知识的一层更精细的表达，数据集要走向实用，要重视这些细节。

**一些细节**
分类时，无法判别的样本，学术界通常丢弃，实用过程中不能丢弃，设置为无法判别类

有时候分类可能在不同的专业领域分类方法不同，比如服装，在设计领域，商家领域，消费者领域各有不同

