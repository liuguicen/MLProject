语言[20,8]和视觉[32,13]大规模模型的最新进展表明，强大的表示有助于解决多个下游任务。同样，我们推测，无论具体设置如何，良好的表现可能会使许多不同的跟踪任务受益。为了验证我们的推测，在本文中，我们提出了一个框架，允许采用相同的外观模型来处理五个不同的跟踪任务（图2）。单目标跟踪（SOT），视频物体分割（VOS），多目标跟踪（MOT），多目标跟踪分割（MOTS），姿态跟踪（PoseTrack）
![](img_2.png)


在我们的分类（图4）中，我们将现有的跟踪任务视为在其核心具有传播或关联的问题。当核心问题是传播（如SOT和VOS）时，必须根据目标对象在前一帧中的位置，在当前帧中定位目标对象。相反，在关联问题（MOT、MOT和PoseTrack）中，会给出前一帧和当前帧中的目标状态，目标是确定两组观测值之间的对应关系。 

对于传播任务，我们使用现有的框和掩码传播算法[7,84,81]。对于关联任务，我们提出了一种新的基于重构的度量方法，它利用细粒度的对应关系来度量观测值之间的相似性。

在提出的框架中，每个单独的任务被分配给一个专用的“头部”，该头部允许以适当的格式表示对象，以便与相关基准上的现有技术进行比较。

请注意，在我们的框架中，只有外观模型包含可以通过反向传播学习的参数，并且我们不使用经过特定跟踪任务训练的外观模型进行实验。相反，我们采用了通过最近的自我监督学习（SSL）技术训练的模型。好处之一是应用上可以立即用于新的数据集和任务，而无需再培训。

图3描述了提出的UniTrack框架的示意图概述，可以理解为在概念上分为三个“级别”。第一级由外观模型表示，负责从输入帧中提取高分辨率特征图（第2.2节）。第二级由算法原语组成，用于处理传播（第2.3节）和关联（第2.4节）。最后，最后一级包含多个特定于任务的算法，这些算法直接使用第二级的原语。


姿势传播。就是传播heatmap。


B.2掩模和姿势传播在第2.3节中，我们介绍了递归掩模传播zt=Kttt1ztt1。实际上，为了提供更多的时间上下文，我们使用由多个前标签映射组成的内存库[42,36]作为源标签zm


算法运动提示：对象状态和卡尔曼滤波。在关联型算法中，我们采用了一个恒速度和线性运动模型的卡尔曼滤波器来处理运动线索。我们假设一个普通的设置，相机没有校准，自我运动未知。对象状态在八维空间（u、v、γ、h、˙u、˙v、˙γ、˙h）中定义，其中（u、v）表示包围框中心的位置，h表示包围框高度，γ=hw表示纵横比。后四维分别代表前四项的速度。

我们使用（平方）马氏距离[91]来测量新到达的检测和现有轨迹之间的“运动距离”。让我们将第i个轨迹的状态分布投影到测量空间中，并将平均值和协方差分别表示为µi和∑i。然后，运动距离由

如果检测无法将现有的tracklet与算法1匹配，它可能对应于一个新的tracklet。然而，这将导致频繁创建简短的“伪”轨迹，只包含一个检测。为了解决这个问题，与[91]类似，我们仅在两个连续帧中出现新检测时（且连续框之间的IOU至少为0.8）才会初始化新的tracklet。


