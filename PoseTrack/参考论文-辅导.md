研究目标：
实时的单人追踪和姿势检测
# 参考文献和实现方法
## 单目标跟踪
### 单目标跟踪排行：
https://paperswithcode.com/sota/visual-object-tracking-on-lasot

https://paperswithcode.com/sota/visual-object-tracking-on-vot201718

### 最新论文sota
2021年的单目标跟踪综述
https://www.arocmag.com/article/02-2021-10-003.html

目前排名第二的论文-主要是cnn和transformer结合的
https://paperswithcode.com/paper/learning-spatio-temporal-transformer-for
主要实现思路，相比如传统的单目标追踪，增加了一个时空信息网络，将目标图像和搜索区域图像，时空信息网络获取的数据，一起送入cnn的backbone，然后拼接backbone输出的特征，输入transformer，再从transformer输出的特征中利用fcn预测目标框。
![](.思路_images/db356cf7.png)
这篇论文的作者在github还提供了轻量版的设计，在使用ONNXRUNTIME来进一步加速推理，加速后的STARK-Lightning在RTX TITAN上的运行速度可达200+ FPS 


2021.12.2 出的最新的sota,基于纯transformer架构
https://arxiv.org/abs/2112.00995
![](.思路_images/d7d2accd.png)
这个大概就是使用swin-transformer结构的多头只注意力堆叠的网络提取特征，然后使用transformer来融合特征，最后预测

2021多目标跟踪上实现了大步前进的sota，可能有借鉴意义
https://arxiv.org/abs/2110.06864
 
 
 
## 单人目标跟踪
展示没有找到相关的论文

## 多人目标跟踪
https://arxiv.org/pdf/2112.04477.pdf
2012.12出的多人目标跟踪sota，它的思路和一般的多目标跟踪类似，但是结合了人类的特征，具体的说
先利用人体分割网络分割出人体，然后用3D相关的网络提取人体的3D位置，3D关键点，3D外貌，然后根据上述3种对象的多帧的状态，预测未来若干帧的状态，然后与当前帧中提取的位置，关键点，外貌等进行对比，利用一些贝叶斯概率之类的计算，判断它们是否属于同一个人，从而实现跟踪。

## 人体关键点检测
BlazePose 专门为移动端优化了人体姿势检测，能够在移动端实时检测单人姿势
会先检测人脸，然后根据人脸推断整个人体为范围，然后人体关键点，没有人脸的情况下怎么检测似乎没看到，实际效果是能检测的
然后没有重新识别的机制的，只是简单的在相邻区域寻找人脸（人体），如果出现遮挡或者另一个人靠近就容易出现丢失。

## 综合检测
https://google.github.io/mediapipe/solutions/holistic.html
MediaPipe的Hostlic检测流程是，用BlazePose先检测姿势，然后根据姿势判断和预测人手，人脸的区域，然后把该区域的图像裁剪下来检测人脸人手的关键点。
这个Hostlic是基于BlazePose，所以同样是没有重新识别的机制的，只是简单的在相邻区域寻找人体，如果出现遮挡或者另一个人靠近就容易出现丢失。

## 整体流程
单目标人体跟踪-根据检测到的目标框调用mediapipe的hostlic算法-根据算法给出的关键点实现动态贴纸

## 人体关键点检测
拟采用人体关键点检测，采用google开源的mediapipe库
https://google.github.io/mediapipe/solutions/holistic