初始化时首先检测人体框，然后在人体框类检测人体姿势，后面的帧首先通过前面的人体姿势预估一个人体范围框，然后从范围框里面检测人体姿势，然后使用姿势匹配方法（SGCN）进行身份关联实现跟踪，

如果检测并且关联成功，然后就用姿势框作为人体框，然后继续下一帧，循环。

如果发现检测或者关联失败，那么重新调用检测算法，检测人体框，再检测姿势，再进行关联，循环 


代码算法流程:
OpenCV读取帧，然后遍历所有帧，

如果是关键帧(里面的判断关键帧的方式是简单的x比如10的倍数作为关键帧) 
检测关键帧里面的所有的人体框，然后遍历每个人体框
先用空间关联度进行关联追踪，就是IOU大于阈值
如果用空间关联没有关联上，再用GCN做姿势关联
如果都没有关联上，就赋予一个新的ID

如果是非关键帧，根据当前帧的关键点获取下一帧的搜索框，在框里面检测关键点，然后根据关键点判断是否是同一个目标(判断方法大概是简单比较关键点平均置信度大于阈值，不是gcn)，
获取目标框
 


# 参数量和计算量
只用到3个子网络

人体检测网络：
用的YOLOv3 相当大，YOLOv3的tiny版本大小也是35M
现在的目标检测网络已经甩了这个几条街了，百度的picodet轻量化1MB和精度对超过YOLOv5，超过v3应该也是一定的

姿势估计网络:
默认使用的姿态估计网络参数量有113M，不知道是哪个网络，论文里面好像也没提到
这个网络还只是检测了热度图，获取关键点还是通过后处理得到的
这里同样的，最新的姿态检测网络轻量化已经做得很小了，百度开源的pp-tinypose速度几毫秒一帧，大小6m多

姿势关联网络：
这个网络很小 100kb不到


其它的，代码里面很多的前后处理，不是网络模型相关的

存在的问题：
人体姿态和位置变化很大，那么就会出现跟踪丢失问题
人体不完整，即姿态不完整，就会出现问题
人体交错之后容易混掉

跨境头跟踪问题


# 改造
很多代码可以使用paddle里面的 比如指标计算






