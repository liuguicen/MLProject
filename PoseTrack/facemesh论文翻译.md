The landmarks are used to rotate a facial rectangle to align the line  connecting the eye centers with the horizontal axis of the rectangle.   这些地标用于旋转面部矩形，使连接眼睛中心的线与矩形的水平轴对齐。
A rectangle obtained in the previous step is cropped from the original image and resized so as to form the input to the mesh prediction neural network (ranging in size from 256×256 pixels in the full model to 128×128 in the smallest one). This model produces a vector of 3D landmark coordinates, which subsequently gets mapped back into the original image coordinate system. A distinct scalar network output (face flag) produces the probability of the event that a reasonably aligned face is indeed present in the provided crop.
在上一步中获得的矩形从原始图像中裁剪并调整大小，以形成网格预测神经网络的输入（大小从完整模型中的256×256像素到最小模型中的128×128像素）。该模型生成三维地标坐标向量，随后映射回原始图像坐标系。不同的标量网络输出（面标志）产生事件的概率，即在提供的裁剪中确实存在合理对齐的面。

We have adopted the policy that the x- and y-coordinates of the vertices correspond to the point locations in the 2D plane as given by the image pixel coordinates. The zcoordinates are interpreted as the depth relative to a reference plane passing through the mesh’s center of mass. They are re-scaled so that a fixed aspect ratio is maintained between the span of x-coordinates and the span of z-coordinates, i.e. a face that is scaled to half its size has its depth range (nearest to farthest) scaled down by the same multiplier. 
我们采用的策略是，顶点的x和y坐标对应于由图像像素坐标给定的2D平面中的点位置。Z坐标被解释为相对于穿过网格质心的参考平面的深度。它们被重新缩放，以便在x坐标跨度和z坐标跨度之间保持固定的纵横比，即缩放到一半大小的面的深度范围（最接近最远的深度范围）被相同的乘数缩小。

When used on video input in the face tracking mode, a good facial crop is available from the previous frame prediction and the usage of the face detector is redundant. In this scenario, it is only used on the first frame and in the rare events of re-acquisition (after the probability predicted by the face flag falls below the appropriate threshold). It should be noted that with this setup, the second network receives the inputs with faces reasonably centered and aligned. We argue that this allows to save some model representational capacity that could otherwise be spent on handling the cases with substantial rotation and translation. In particular, we could reduce the amount of related augmentations while gaining prediction quality.
在人脸跟踪模式下用于视频输入时，可以从之前的帧预测中获得良好的人脸裁剪，并且人脸检测器的使用是多余的。在这种情况下，它仅在第一帧和罕见的重新捕获事件中使用（在面部标志预测的概率低于适当阈值之后）。应该注意的是，通过这种设置，第二个网络接收面合理居中和对齐的输入。我们认为，这可以节省一些模型表征能力，否则这些能力可能会用于处理大量旋转和平移的情况。特别是，我们可以减少相关增强的数量，同时获得预测质量。


5. Filtering for temporal consistency in video
Since our model is operating on a single-frame level, the only information that gets passed between frames is the rotated facial bounding rectangle (and whether or not it should be re-evaluated with face detector). Because of the inconsistencies in pixel-level image representations of faces across subsequent video frames (due to small affine transforms of the view, head pose change, lighting variation, as well as different kinds of camera sensor noise [8]), this leads to human-noticeable fluctuations, or temporal jitter, in the trajectories of individual landmarks (although the entire mesh as a surface is less affected by this phenomenon). 
由于我们的模型是在单帧级别上运行的，帧之间传递的唯一信息是旋转的面部边界矩形（以及是否应该使用面部检测器重新评估）。由于后续视频帧中人脸的像素级图像表示不一致（由于视图的小仿射变换、头部姿势变化、照明变化以及不同类型的相机传感器噪声[8]），这会导致人类明显的波动或时间抖动，在各个地标的轨迹中（尽管作为曲面的整个网格受此现象的影响较小）

We propose to address this issue by employing a one dimensional temporal filter applied independently to each predicted landmark coordinate. As the primary application of our proposed pipeline is visually appealing rendering, we draw inspiration from human-computer interaction methods, specifically the 1 Euro filter [5]. The main premise of 1 Euro and related filters is that in the trade-off between noise reduction and phase lag elimination, humans prefer the former (i.e. stabilization) when the parameters are virtually not changing and the latter (i.e. avoiding the lag) when the rate of change is high. Our filter maintains a fixed rolling window of a few timestamped samples for velocity estimations, which are adjusted by the face size to accommodate for face scale changes in a video stream. Using this filter leads to human-appealing prediction sequences on videos without visible jitter.
**我们建议通过对每个预测的地标坐标单独应用一维时间滤波器来解决这个问题。**由于我们提出的管道的主要应用是具有视觉吸引力的渲染，我们从人机交互方法中获得了灵感，特别是1欧元过滤器[5]。1欧元及相关滤波器的主要前提是，在降噪和消除相位滞后之间进行权衡时，当参数几乎不变时，人类更喜欢前者（即稳定），而当变化率较高时，人类更喜欢后者（即避免滞后）。我们的过滤器为速度估计维护了几个时间戳样本的固定滚动窗口，速度估计由面部大小调整，以适应视频流中面部比例的变化。使用此过滤器可以在视频上生成吸引人的预测序列，而不会产生可见的抖动。