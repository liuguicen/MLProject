总结：模型大小有602M 256的图片
逐渐形成的一个思想是，GAN不仅能生成图片，它内部还学习到了很多图片的知识，报考语义信息，我们可以将这些知识利用起来。

最近的工作表明训练GAN从隐空间合成图像时隐空间出现了多种语义信息，但是很难用这些语义信息对真实图像进行编辑。常用的方法是先将真实图像反向映射到隐空间。但是现在的方法聚焦于像素重建，没有成功地将映射后的代码置于原始隐空间的语义领域。我们首先学习一个新颖的领域引导的编码器，将图片映射到GAN的隐空间。然后提出了域正则化优化，通过将编码器作为一个正则化器来微调由编码器产生的编码，并更好地恢复目标图像。大量的实验表明，我们的反演方法实现了令人满意的真实图像重建，更重要的是促进了各种图像编辑任务，显著优于现有技术。

引言：
GAN。。。
传统的GAN Inversion聚焦在像素级的重现原来的图片，但是存在很多的问题，比如，翻转编码是否属于原始GAN的隐空间？反转编码是否语义上代表了原始图片？翻转编码是否能在利用GAN学到的知识的情况下进行图片编辑？在这项工作中，我们证明了一种好的GAN反演方法不仅应该在像素级重建目标图像，而且还应该将反向的代码与在潜空间中编码的语义知识对齐。我们将这些具有语义意义的代码称为域内代码，因为它们服从GANs学习到的语义域。我们还发现，域内代码通过重用GAN模型中出现的丰富知识，可以更好地支持图像编辑。我们提出了一种域内GAN反演方法来**在像素层面和语义层面上恢复输入图像**在这里，语义指的是GAN从观测数据[11,16,30,32]中自发学到的知识。

还有的考虑设计可以反推的GAN架构来实现GAN Inversion

一些同时期的用于提高GAN Inversion的工作：使用多个反演编码，或者GAN的参数随着反演一起更新，或者类似StyleGAN考虑层级的噪声

如果代码不能与潜在空间的语义域对齐，即使能够恢复输入图像的每像素值，它仍然无法重用GANs学到的知识进行语义编辑。 我们从语义层面深入研究了反向代码的性质，并提出了良好支持真实图像编辑的域内GAN反演。

符号和问题定义：z^inv表示反向的潜编码 GAN学到的隐空间S。
目前，StyleGAN出来之后，GAN Inversion 大都选择w空间了。
本文也选择w空间。通过GAN前面增加一个MLP可以将W空间转换到S空间，方便一般的GAN使用。

模型结构： 
![](.In-Domain GAN Inversion-论文笔记_images/4e1f6337.png)
上面是传统的结构，下面是本文的
传统的简单些，不用真实图片训练，直接隐空间采用，生成，解码，对比损失，反传

本文的相当于加了几个额外的约束，让编码器能够更好的对齐语义信息
损失函数如下 
![](.In-Domain GAN Inversion-论文笔记_images/d7dff117.png)
增加了判别器进行判别，判别器是要训练的，不是固定的
使用真实图片，编码，解码，然后对比图片，
增加VGG感知损失来对比
