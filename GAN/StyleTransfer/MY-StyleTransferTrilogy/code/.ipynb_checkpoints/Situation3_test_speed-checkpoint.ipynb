{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:29:56.485931Z",
     "start_time": "2018-07-16T07:29:56.461885Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import random\n",
    "import shutil\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import *\n",
    "from models import *\n",
    "from matplotlib import pyplot as plt\n",
    "from Thirdutils import imshow, read_image, mean_std, tensor_normalizer\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:11:35.521914Z",
     "start_time": "2018-07-16T07:11:35.517465Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def rmrf(path):\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for f in glob('runs/*/.AppleDouble'):\n",
    "    rmrf(f)\n",
    "\n",
    "rmrf('runs/metanet')\n",
    "rmrf('runs/transform_net')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:11:41.245005Z",
     "start_time": "2018-07-16T07:11:35.524128Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)\n",
    "vgg16 = VGG(vgg16.features[:23]).to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:11:41.295795Z",
     "start_time": "2018-07-16T07:11:41.247195Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'downsampling.5': 18496,\n",
       "             'downsampling.9': 73856,\n",
       "             'residuals.0.conv.1': 147584,\n",
       "             'residuals.0.conv.5': 147584,\n",
       "             'residuals.1.conv.1': 147584,\n",
       "             'residuals.1.conv.5': 147584,\n",
       "             'residuals.2.conv.1': 147584,\n",
       "             'residuals.2.conv.5': 147584,\n",
       "             'residuals.3.conv.1': 147584,\n",
       "             'residuals.3.conv.5': 147584,\n",
       "             'residuals.4.conv.1': 147584,\n",
       "             'residuals.4.conv.5': 147584,\n",
       "             'upsampling.2': 73792,\n",
       "             'upsampling.7': 18464})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = 32\n",
    "transform_net = TransformNet(base).to(device)\n",
    "transform_net.get_param_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:11:41.301261Z",
     "start_time": "2018-07-16T07:11:41.297411Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformNet(\n",
       "  (downsampling): Sequential(\n",
       "    (0): ReflectionPad2d((4, 4, 4, 4))\n",
       "    (1): Conv2d(3, 32, kernel_size=(9, 9), stride=(1, 1))\n",
       "    (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU()\n",
       "    (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (5): MyConv2D(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): ReLU()\n",
       "    (8): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (9): MyConv2D(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (10): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (11): ReLU()\n",
       "  )\n",
       "  (residuals): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): MyConv2D(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU()\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): MyConv2D(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): MyConv2D(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU()\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): MyConv2D(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): MyConv2D(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU()\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): MyConv2D(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): MyConv2D(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU()\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): MyConv2D(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): MyConv2D(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU()\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): MyConv2D(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upsampling): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (1): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (2): MyConv2D(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): ReLU()\n",
       "    (5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (6): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (7): MyConv2D(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (8): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (9): ReLU()\n",
       "    (10): ReflectionPad2d((4, 4, 4, 4))\n",
       "    (11): Conv2d(32, 3, kernel_size=(9, 9), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:11:41.314241Z",
     "start_time": "2018-07-16T07:11:41.302712Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class MetaNet(nn.Module):\n",
    "    def __init__(self, param_dict):\n",
    "        super(MetaNet, self).__init__()\n",
    "        self.param_num = len(param_dict)\n",
    "        self.hidden = nn.Linear(1920, 128*self.param_num)\n",
    "        self.fc_dict = {}\n",
    "        for i, (name, params) in enumerate(param_dict.items()):\n",
    "            self.fc_dict[name] = i\n",
    "            setattr(self, 'fc{}'.format(i+1), nn.Linear(128, params))\n",
    "    \n",
    "    # ONNX 要求输出 tensor 或者 list，不能是 dict\n",
    "    def forward(self, mean_std_features):\n",
    "        hidden = F.relu(self.hidden(mean_std_features))\n",
    "        filters = {}\n",
    "        for name, i in self.fc_dict.items():\n",
    "            fc = getattr(self, 'fc{}'.format(i+1))\n",
    "            filters[name] = fc(hidden[:,i*128:(i+1)*128])\n",
    "        return list(filters.values())\n",
    "    \n",
    "    def forward2(self, mean_std_features):\n",
    "        hidden = F.relu(self.hidden(mean_std_features))\n",
    "        filters = {}\n",
    "        for name, i in self.fc_dict.items():\n",
    "            fc = getattr(self, 'fc{}'.format(i+1))\n",
    "            filters[name] = fc(hidden[:,i*128:(i+1)*128])\n",
    "        return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:11:43.343014Z",
     "start_time": "2018-07-16T07:11:41.315603Z"
    },
    "code_folding": [],
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metanet = MetaNet(transform_net.get_param_dict()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:11:43.348128Z",
     "start_time": "2018-07-16T07:11:43.344788Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaNet(\n",
       "  (hidden): Linear(in_features=1920, out_features=1792, bias=True)\n",
       "  (fc1): Linear(in_features=128, out_features=18496, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=73856, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=147584, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=147584, bias=True)\n",
       "  (fc5): Linear(in_features=128, out_features=147584, bias=True)\n",
       "  (fc6): Linear(in_features=128, out_features=147584, bias=True)\n",
       "  (fc7): Linear(in_features=128, out_features=147584, bias=True)\n",
       "  (fc8): Linear(in_features=128, out_features=147584, bias=True)\n",
       "  (fc9): Linear(in_features=128, out_features=147584, bias=True)\n",
       "  (fc10): Linear(in_features=128, out_features=147584, bias=True)\n",
       "  (fc11): Linear(in_features=128, out_features=147584, bias=True)\n",
       "  (fc12): Linear(in_features=128, out_features=147584, bias=True)\n",
       "  (fc13): Linear(in_features=128, out_features=73792, bias=True)\n",
       "  (fc14): Linear(in_features=128, out_features=18464, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metanet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出计算图到 tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:11:49.081766Z",
     "start_time": "2018-07-16T07:11:43.349487Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\jit\\__init__.py:1109: TracerWarning: Encountering a list at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.\n",
      "  module._c._create_method_from_trace(method_name, func, example_inputs, var_lookup_fn, strict, _force_outplace)\n"
     ]
    }
   ],
   "source": [
    "mean_std_features = torch.rand(4, 1920).to(device)\n",
    "writer = SummaryWriter('runs/metanet')\n",
    "writer.add_graph(metanet, (mean_std_features, ))\n",
    "\n",
    "rands = torch.rand(4, 3, 256, 256).to(device)\n",
    "writer = SummaryWriter('runs/transform_net')\n",
    "writer.add_graph(transform_net, (rands, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:11:50.002543Z",
     "start_time": "2018-07-16T07:11:49.125103Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/metanet_base32_style50_tv1e-06_tagnohvd.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0e48808db0cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmetanet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/metanet_base32_style50_tv1e-06_tagnohvd.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtransform_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/metanet_base32_style50_tv1e-06_tagnohvd_transform_net.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/metanet_base32_style50_tv1e-06_tagnohvd.pth'"
     ]
    }
   ],
   "source": [
    "metanet.load_state_dict(torch.load('models/metanet_base32_style50_tv1e-06_tagnohvd.pth'))\n",
    "transform_net.load_state_dict(torch.load('models/metanet_base32_style50_tv1e-06_tagnohvd_transform_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:11:50.008225Z",
     "start_time": "2018-07-16T07:11:50.004337Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = torch.rand((1, 3, 256, 256)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:11:58.741037Z",
     "start_time": "2018-07-16T07:11:50.009759Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    features = vgg16(X)\n",
    "    mean_std_features = mean_std(features)\n",
    "    weights = metanet.forward2(mean_std_features)\n",
    "    transform_net.set_weights(weights)\n",
    "    del features, mean_std_features, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:12:03.398990Z",
     "start_time": "2018-07-16T07:11:58.742772Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    transform_net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:12:16.812579Z",
     "start_time": "2018-07-16T07:12:03.400629Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    features = vgg16(X)\n",
    "    mean_std_features = mean_std(features)\n",
    "    weights = metanet.forward2(mean_std_features)\n",
    "    transform_net.set_weights(weights)\n",
    "    transform_net(X)\n",
    "    del features, mean_std_features, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:12:17.545068Z",
     "start_time": "2018-07-16T07:12:16.814712Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "width = 256\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(width, scale=(256/480, 1), ratio=(1, 1)), \n",
    "    transforms.ToTensor(), \n",
    "    tensor_normalizer\n",
    "])\n",
    "\n",
    "style_dataset = torchvision.datasets.ImageFolder('/home/ypw/WikiArt/', transform=data_transform)\n",
    "content_dataset = torchvision.datasets.ImageFolder('/home/ypw/COCO/', transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:12:17.549058Z",
     "start_time": "2018-07-16T07:12:17.546846Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# epoch = 19\n",
    "# metanet.load_state_dict(torch.load(\n",
    "#     f'checkpoints/metanet_base32_style50_tv1e-06_tag1_{epoch}.pth'))\n",
    "# transform_net.load_state_dict(torch.load(\n",
    "#     f'checkpoints/metanet_base32_style50_tv1e-06_tag1_transform_net_{epoch}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:30:49.328131Z",
     "start_time": "2018-07-16T07:30:49.320131Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "style_weight = 50\n",
    "content_weight = 1\n",
    "tv_weight = 1e-6\n",
    "batch_size = 8\n",
    "\n",
    "trainable_params = {}\n",
    "trainable_param_shapes = {}\n",
    "for model in [vgg16, transform_net, metanet]:\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            trainable_params[name] = param\n",
    "            trainable_param_shapes[name] = param.shape\n",
    "\n",
    "optimizer = optim.Adam(trainable_params.values(), 1e-3)\n",
    "content_data_loader = torch.utils.data.DataLoader(content_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:45:30.585462Z",
     "start_time": "2018-07-16T07:45:21.186899Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "style_image = read_image('../images/test.jpg', target_width=256).to(device)\n",
    "style_features = vgg16(style_image)\n",
    "style_mean_std = mean_std(style_features)\n",
    "\n",
    "metanet.load_state_dict(torch.load('models/metanet_base32_style50_tv1e-06_tagnohvd.pth'))\n",
    "transform_net.load_state_dict(torch.load('models/metanet_base32_style50_tv1e-06_tagnohvd_transform_net.pth'))\n",
    "\n",
    "n_batch = 20\n",
    "with tqdm(enumerate(content_data_loader), total=n_batch) as pbar:\n",
    "    for batch, (content_images, _) in pbar:\n",
    "        x = content_images.cpu().numpy()\n",
    "        if (x.min(-1).min(-1) == x.max(-1).max(-1)).any():\n",
    "            continue\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 使用风格图像生成风格模型\n",
    "        weights = metanet.forward2(mean_std(style_features))\n",
    "        transform_net.set_weights(weights, 0)\n",
    "\n",
    "        # 使用风格模型预测风格迁移图像\n",
    "        content_images = content_images.to(device)\n",
    "        transformed_images = transform_net(content_images)\n",
    "\n",
    "        # 使用 vgg16 计算特征\n",
    "        content_features = vgg16(content_images)\n",
    "        transformed_features = vgg16(transformed_images)\n",
    "        transformed_mean_std = mean_std(transformed_features)\n",
    "\n",
    "        # content loss\n",
    "        content_loss = content_weight * F.mse_loss(transformed_features[2], content_features[2])\n",
    "\n",
    "        # style loss\n",
    "        style_loss = style_weight * F.mse_loss(transformed_mean_std, \n",
    "                                               style_mean_std.expand_as(transformed_mean_std))\n",
    "\n",
    "        # total variation loss\n",
    "        y = transformed_images\n",
    "        tv_loss = tv_weight * (torch.sum(torch.abs(y[:, :, :, :-1] - y[:, :, :, 1:])) + \n",
    "                                torch.sum(torch.abs(y[:, :, :-1, :] - y[:, :, 1:, :])))\n",
    "\n",
    "        # 求和\n",
    "        loss = content_loss + style_loss + tv_loss \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch > n_batch:\n",
    "            break\n",
    "\n",
    "content_images = torch.stack([random.choice(content_dataset)[0] for i in range(4)]).to(device)\n",
    "# while content_images.min() < -2:\n",
    "#     print('.', end=' ')\n",
    "#     content_images = torch.stack([random.choice(content_dataset)[0] for i in range(4)]).to(device)\n",
    "transformed_images = transform_net(content_images)\n",
    "\n",
    "transformed_images_vis = torch.cat([x for x in transformed_images], dim=-1)\n",
    "content_images_vis = torch.cat([x for x in content_images], dim=-1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.subplot(3, 1, 1)\n",
    "imshow(style_image)\n",
    "plt.subplot(3, 1, 2)\n",
    "imshow(content_images_vis)\n",
    "plt.subplot(3, 1, 3)\n",
    "imshow(transformed_images_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:33:40.376009Z",
     "start_time": "2018-07-16T07:33:38.156300Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# style_image = random.choice(style_dataset)[0].unsqueeze(0).to(device)\n",
    "style_image = read_image('../images/mosaic.jpg', target_width=256).to(device)\n",
    "# style_image = style_image[:,[2, 1, 0]]\n",
    "features = vgg16(style_image)\n",
    "mean_std_features = mean_std(features)\n",
    "weights = metanet.forward2(mean_std_features)\n",
    "transform_net.set_weights(weights)\n",
    "\n",
    "content_images = torch.stack([random.choice(content_dataset)[0] for i in range(4)]).to(device)\n",
    "# while content_images.min() < -2:\n",
    "#     print('.', end=' ')\n",
    "#     content_images = torch.stack([random.choice(content_dataset)[0] for i in range(4)]).to(device)\n",
    "transformed_images = transform_net(content_images)\n",
    "\n",
    "transformed_images_vis = torch.cat([x for x in transformed_images], dim=-1)\n",
    "content_images_vis = torch.cat([x for x in content_images], dim=-1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.subplot(3, 1, 1)\n",
    "imshow(style_image)\n",
    "plt.subplot(3, 1, 2)\n",
    "imshow(content_images_vis)\n",
    "plt.subplot(3, 1, 3)\n",
    "imshow(transformed_images_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "40",
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "441px",
    "left": "934px",
    "right": "20px",
    "top": "120px",
    "width": "333px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
