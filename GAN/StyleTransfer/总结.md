# 总结：
很多论文都有修饰的成分， 说什么实时，实际上都是不行的，在训练的GPU上实时，根本无法实用
说什么效果更好，很多也是没有的，都是挑选的对自己有利的图片，实际根本没有，所以要注意到论文中展示改进了一点的论文基本上等于没有改进
相比adain优势不是很明显，cpu情况下速度比较快
同一种内容图 图片大小  1080 * 1460

|     |MetaStyle |  adain | 号称可以实时运行的     |
                             StyleTransferTrilogy
|-----|----------|--------| --------------------- |
|gpu  |   1.16s  |  1.27s | 5s
|cpu  |   1.17s  |  16s   | no data

StyleTransferTrilogy 是降到了256*256，在原作者的1080ti+并行化处理4.5ms， 自己电脑GPU 没有并行化 0.3s
## 手机上 
 图片大小  1080 * 1460
   
|     |  adain未优化  |   adain优化  | metastyle|  linearStyle |
|-----| -------------| -------------| ------   | ----------   |
|速度  | 9059ms      |  5500ms      | 4164ms   |   8xxxms     |
|内存  | 1.6GB        | 1.6GB        | 1.1GB   |   1.6GB      |

linearStyle 没有明显的优势，速度和图像质量上
# 关于内容图与风格图相对大小
从adain看，风格图比内容图大2倍，有时候更大，得出的效果看上去最好，最细腻，如果小了，就会呈现不真实的斑块状
有用的是，主动缩小内容图像也能达到类似的效果
也就是说保持风格图大小不变，将内容图缩小到风格图的约1/2
由此应该可以对训练过程做一定的优化，adain训练时是相同大小的，优化可以改用不同的大小

另一个方向：
前面的风格迁移迁移之后的图像偏向艺术化，也就是会有些抽象，不具有照片真实度，另一个方向是具有照片真实度的图像风格化，这也是值得做的方向
但是目前来看就像一个滤镜 能对图片做的改变有限 效果不惊艳
https://github.com/limingcv/Photorealistic-Style-Transfer
https://github.com/clovaai/WCT2

# 风格模型进行 蒸馏，深度可分离，是可行的，参考
https://magenta.tensorflow.org/blog/2018/12/20/style-transfer-js/

magenta中有相应的代码原型，不过是tensorflow的 想要明白并不容易
这个库中得出的效果比adain效果好很多，并且是经过上面一系列转化之后的，模型大小5mb，速度200ms以内，但是官方只提供了384*384的固定尺寸的预训练模型

但是对于部分图片，adain的效果会好些

# 注意StyleTransfer和GAN的区别
注意，一般的风格迁移不是用的GAN的模式，它生成图片时是用的更为一般的编码器解码器模式，从这个角度看的话，简单理解的话它的效果相对GAN会差一些是不是？

风格图片效果要测试的内容图：
1、人脸
2、整个人体
3、合照
4、风景—山水   
5、风景-花草树木
6、城市-远景
7、城市-近景
8、加剧
9、宠物动物
10、食物

